# Architecture Decision Records (ADRs)

This document captures the **final architecture decisions for this repository**, based on the end-to-end workflow described in `Workflow.md`: how the workflow is modeled, why each infrastructure piece exists, and what trade-offs were accepted.

Format: **Context → Decision → Consequences**.

---

## ADR-001 — Event-driven, asynchronous order workflow

**Status:** Accepted

### Context
Orders must be accepted quickly, while processing is performed asynchronously. The UX still needs “near real-time” completion feedback.

### Decision
Split the workflow into an intake boundary and asynchronous workers:
- `order-accept` responds immediately and publishes `OrderAccepted`.
- `order-process` performs the OLTP transaction and publishes `OrderProcessed`.
- `order-notification` pushes real-time updates over SignalR.

### Consequences
- The system is **eventually consistent**: acceptance ≠ completion.
- The ingestion path is resilient to downstream latency.
- Observability (correlation) becomes a first-class requirement.

---

## ADR-002 — Use CorrelationId as the workflow key (separate from OrderId)

**Status:** Accepted

### Context
The user-facing business identity (`OrderId`) is generated by SQL, but the system must track workflow state before and across asynchronous hops.

### Decision
Use two identifiers:
- `CorrelationId` (UUID) — generated at intake; the end-to-end workflow key.
- `OrderId` (long) — generated by SQL during persistence; business identity.

### Consequences
- The UI can track an order immediately via `CorrelationId`.
- Workers can enforce idempotency on `CorrelationId`.
- Traces/logs can be correlated across HTTP, messaging, Redis, and SignalR.

---

## ADR-003 — Do not embed SignalR routing identity in broker messages

**Status:** Accepted

### Context
The notification service needs to know “who to notify”. Including routing identity in broker messages increases coupling and risk of propagating identity data widely.

### Decision
Broker messages do not carry SignalR routing metadata. Instead:
- `order-accept` stores an ephemeral mapping `CorrelationId → userId` in Redis.
- `order-notification` resolves `userId` from Redis at notification time.

### Consequences
- Messages stay clean and reusable (processing does not need to know about notification routing).
- Redis becomes a critical but **ephemeral** dependency for “instant notifications”.
- Missing mappings are handled via retries + DLQ (not silent drops).

---

## ADR-004 — Store transient workflow state in Redis (TTL-based)

**Status:** Accepted

### Context
WebSockets are transient; users may open multiple tabs, refresh, or reconnect. The UI needs a shared, low-latency place to read “current workflow state”.

### Decision
Persist transient workflow state in Redis using TTL keys:
- `order:status:{CorrelationId} = ACCEPTED | PROCESSING | COMPLETED|{orderId}`
- `order:map:{CorrelationId} = {userId}`

`order-process` refreshes TTL while processing.

### Consequences
- Fast UX state reads and reconnection “rehydration”.
- Redis is not a system of record: expiry is acceptable, but it can degrade UX.
- TTL values must be chosen to cover expected processing time and reconnection windows.

---
## ADR-005 Real-time Notifications (SignalR) and Scale-Out

### Decision
Use **ASP.NET Core SignalR** for real-time order updates, and enable **scale-out** with a **Redis backplane** (`Microsoft.AspNetCore.SignalR.StackExchangeRedis`) using the project’s existing Redis instance. Backplane pub/sub traffic is isolated with a Redis **`ChannelPrefix`** (e.g., `contoso-signalr`).

### Rationale
- **Multi-pod fan-out:** when a worker calls `Clients.User(userId)`, the sending pod publishes the message to Redis pub/sub; *all* SignalR pods receive it and forward it to their **local WebSocket connections** for that `userId`. This ensures a user with multiple tabs/devices connected to different pods still receives every notification.
- **Redis reuse without collisions:** the same Redis instance can store `order:*` workflow keys and also carry backplane pub/sub. Using a **`ChannelPrefix`** prevents backplane channels from colliding with other Redis pub/sub consumers and keeps the backplane logically isolated.
- **No PII in messages:** the Hub targets users via `Context.UserIdentifier` derived from the JWT (`sub`), while the workflow uses Redis `order:map:{correlationId} -> userId` mapping. Service Bus events do not contain `userId`.

---

## Sticky Sessions (Ingress-pod Affinity)

### Decision
Do **not** rely on sticky sessions / ingress affinity for SignalR.

### Rationale
- **Portability and simplicity:** sticky sessions couple correctness to a specific ingress/controller configuration and increase operational complexity.
- **Load distribution:** WebSockets are long-lived by nature; affinity can lead to uneven pod utilization when many clients stay pinned to the same endpoints.
- **Deterministic connection establishment:** the client forces **WebSockets-only** with **`skipNegotiation: true`** so the SignalR connection is established in a single WebSocket hop. This avoids the classic cross-pod `/negotiate` vs WebSocket upgrade mismatch.
- **Resilience during scale events:** when pods scale in/out, existing sockets may drop, but clients automatically reconnect to any healthy pod and rehydrate state (e.g., by re-querying current order status backed by Redis TTL state).
#

---

## ADR-006 — Azure Service Bus in cloud, RabbitMQ locally (via abstractions)

**Status:** Accepted

### Context
Azure Service Bus has no official local emulator. The repo must be runnable end-to-end on a developer machine.

### Decision
- Use RabbitMQ in local development and integration tests.
- Keep code broker-agnostic via `IMessagePublisher` / listener abstractions.
- Use Azure Service Bus in cloud deployments.

### Consequences
- Local validation of distributed behavior is possible.
- Some semantics differ between brokers; tests focus on contracts and at-least-once behavior rather than exact broker feature parity.

---

## ADR-007 — At-least-once delivery + idempotent consumers

**Status:** Accepted

### Context
Both Service Bus and RabbitMQ deliver messages at least once under retries. Duplicate delivery must not create duplicate orders.

### Decision
Make consumers idempotent using `CorrelationId`:
- `order-process` checks whether an order for `CorrelationId` already exists.
- If it exists, it **reuses** the existing `OrderId` and can still publish `OrderProcessed`.

### Consequences
- Safe under redelivery / retries.
- Requires a unique constraint or lookup strategy based on `CorrelationId` in SQL.
- Downstream consumers must also be defensive, since duplicates can propagate.

---

## ADR-008 — No Outbox pattern (rely on retries + idempotency)

**Status:** Accepted (intentional simplification)

### Context
A transactional outbox would guarantee that “persist order” and “publish OrderProcessed” are atomic. It also adds significant complexity.

### Decision
Do not implement outbox in this repository. Instead:
- Persist first.
- Publish afterwards.
- Use retries and idempotency to tolerate transient publish failures.

### Consequences
- There is a narrow window where an order is persisted but the completion message is not published.
- Reprocessing / retries can re-emit `OrderProcessed` safely.
- This is appropriate for a portfolio/demo focus, but would be revisited for production hardening.

---

## ADR-009 — Notification delivery: fail loud if correlation mapping is missing

**Status:** Accepted

### Context
If `order-notification` cannot map `CorrelationId → userId`, it cannot route the message. Silent drops would make failures invisible.

### Decision
- Do a short local retry (100ms → 250ms → 500ms).
- If still missing, throw to trigger broker retry / DLQ.

### Consequences
- Operational visibility: failures become DLQ items rather than silent losses.
- Requires monitoring/alerting on DLQ and consumer exceptions.

---

## ADR-010 — OpenTelemetry + structured logging with correlation propagation

**Status:** Accepted

### Context
Distributed workflows are hard to debug without correlation across services.

### Decision
Implement:
- Serilog structured logs with `CorrelationId` in scope.
- OpenTelemetry traces + metrics (export via OTLP → collector → Jaeger).
- Correlation is taken from the **message payload** and flowed into logs/traces; trace context is propagated via broker headers when available.

### Consequences
- Debugging and “why did this fail?” becomes practical.
- Slight runtime overhead (acceptable for the demo).

---

## ADR-011 — Local HTTPS for SignalR + DEV token endpoint

**Status:** Accepted

### Context
Browsers require WSS for many real scenarios and do not allow custom headers during WebSocket upgrade.

### Decision
- Run `order-notification` with HTTPS locally using a dev PFX certificate mounted into the container.
- Provide `POST /dev/token` (development only) to mint a JWT for the demo SPA.
- Configure SignalR JWT extraction via `?access_token=`.

### Consequences
- Local setup is slightly more involved (dev cert export + trust).
- The repo remains runnable without an external IdP.

---

## ADR-012 — Stateless services, state externalized to SQL + Redis

**Status:** Accepted

### Context
Services must scale horizontally and tolerate restarts without losing correctness.

### Decision
Keep services stateless:
- SQL holds durable business state.
- Redis holds ephemeral workflow/routing state.
- The broker holds transient async work.

### Consequences
- Simple scaling and deploys.
- Requires disciplined boundary definitions and explicit “what is SoR?”.

---

## ADR-013 — Monorepo layout for end-to-end review

**Status:** Accepted

### Context
This repository is intended for technical review and portfolio demonstration.

### Decision
Use a monorepo containing:
- `services/` (three microservices)
- `infra/` (local stack config)
- `frontend/` (demo SPA)
- `design/` (diagrams + notes)

### Consequences
- Easy to run, explore, and review end-to-end.
- Not necessarily how a production organization would split repos.

---